#!/usr/bin/env python3
import sys
import threading
import queue
from utils.analyser.network_loader import load_network, save_network
from utils.analyser.fen_parser import parse_fen
from utils.analyser.training_utils import train_network_multithreaded, one_hot_encode
from utils.analyser.prediction_utils import predict, interpret_prediction


def main(args):
    if len(args) < 3 or (args[1] not in ['--train', '--predict']):
        print("USAGE: ./my_torch_analyzer [--predict | --train [+curve] [--save SAVEFILE]] LOADFILE FILE")
        sys.exit(1)

    mode = args[1]
    curve_enabled = '+curve' in args and args.index('+curve') == args.index('--train') + 1
    load_file = args[args.index('--train') + 2 if curve_enabled else 2]
    input_file = args[args.index('--train') + 3 if curve_enabled else 3]
    save_file = args[args.index('--save') + 1] if '--save' in args else load_file

    # Load the network
    print(f"Loading network from: {load_file}")
    network = load_network(load_file)

    # Load chessboards
    print(f"Loading chessboards from: {input_file}")
    with open(input_file, 'r') as file:
        chessboards = file.readlines()

    data = []
    print(f"Processing {len(chessboards)} chessboards...")
    for idx, fen in enumerate(chessboards):
        try:
            parts = fen.strip().split(' ')
            if len(parts) < 7:
                raise ValueError("Line does not contain enough fields.")
            fen_string = ' '.join(parts[:6])
            label = ' '.join(parts[6:])
            inputs = parse_fen(fen_string)
            data.append((inputs, label))
        except ValueError as e:
            print(f"Error parsing line {idx + 1}: {e}")
            continue

    if mode == '--train':
        print("Training mode...")
        label_map = {
            "Checkmate White": 0,
            "Checkmate Black": 1,
            "Stalemate": 2,
            "Check White": 3,
            "Check Black": 4,
            "Nothing": 5
        }
        num_classes = len(label_map)
        training_data = [(inputs, one_hot_encode(label_map[label], num_classes)) for inputs, label in data]

        # Initialize learning curve if enabled
        curve = None
        updates_queue = queue.Queue()
        stop_flag = threading.Event()

        if curve_enabled:
            try:
                from bonus.learning_curve import LearningCurve
                curve = LearningCurve()
            except ImportError:
                print("Error: Matplotlib is not installed. Cannot use +curve option.")
                sys.exit(1)

        # Start training in a separate thread
        training_thread = threading.Thread(
            target=train_network_multithreaded,
            args=(network, training_data),
            kwargs={
                'learning_rate': 0.005,
                'epochs': 10,
                'batch_size': 72,
                'updates_queue': updates_queue,
                'stop_flag': stop_flag
            }
        )
        training_thread.start()

        try:
            # Main thread handles learning curve updates
            while training_thread.is_alive():
                try:
                    loss, accuracy = updates_queue.get(timeout=0.1)  # Get updates from the queue
                    if curve_enabled and curve:
                        curve.update(loss, accuracy)
                except queue.Empty:
                    continue

            # Finalize curve if enabled
            if curve_enabled and curve:
                curve.finalize()

            # Save trained network
            save_network(network, save_file)
            print(f"Trained network saved to {save_file}")

        except KeyboardInterrupt:
            print("\nTraining interrupted. Stopping...")
            stop_flag.set()  # Signal training thread to stop
            training_thread.join()
            if curve_enabled and curve:
                print("Saving interrupted progress...")
                interrupted_save_file = save_file.replace('.nn', '_interrupted.nn')
                save_network(network, interrupted_save_file)
                print(f"Progress saved to {interrupted_save_file}")
            sys.exit(1)

    elif mode == '--predict':
        print("Prediction mode...")
        for inputs, label in data:
            output = predict(network, inputs)
            prediction = interpret_prediction(output)
            print(f"Prediction: {prediction} | Expected: {label}")

if __name__ == "__main__":
    main(sys.argv)
